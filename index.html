<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="description" content="Improving the accuracy of speech to text recognition through the use of lip reading">
	    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
	    <title>Viseme</title>

	    <link rel="shortcut icon" href="/favicon.ico">
		<link rel="icon" sizes="16x16 32x32 64x64" href="/favicon.ico">
		<link rel="icon" type="image/png" sizes="196x196" href="/favicon-192.png">
		<link rel="icon" type="image/png" sizes="160x160" href="/favicon-160.png">
		<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96.png">
		<link rel="icon" type="image/png" sizes="64x64" href="/favicon-64.png">
		<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16.png">
		<link rel="apple-touch-icon" href="/favicon-57.png">
		<link rel="apple-touch-icon" sizes="114x114" href="/favicon-114.png">
		<link rel="apple-touch-icon" sizes="72x72" href="/favicon-72.png">
		<link rel="apple-touch-icon" sizes="144x144" href="/favicon-144.png">
		<link rel="apple-touch-icon" sizes="60x60" href="/favicon-60.png">
		<link rel="apple-touch-icon" sizes="120x120" href="/favicon-120.png">
		<link rel="apple-touch-icon" sizes="76x76" href="/favicon-76.png">
		<link rel="apple-touch-icon" sizes="152x152" href="/favicon-152.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/favicon-180.png">
		<meta name="msapplication-TileColor" content="#FFFFFF">
		<meta name="msapplication-TileImage" content="/favicon-144.png">
		<meta name="msapplication-config" content="/browserconfig.xml">
		
		<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
		<link href="https://fonts.googleapis.com/css?family=Comfortaa|Open+Sans" rel="stylesheet">
		<link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">
		<script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
		<style>
			body, html {
				background-color: #100007;
				font-family: 'Open Sans', sans-serif !important;
			}

			.mdl-layout__header, .mdl-mini-footer, .mdl-layout__drawer, .mdl-navigation__link {
				background-color: #200116 !important;
				color: #80D39B !important;
			}

			.mdl-layout__drawer {
				border-right: none;
			}

			.mdl-navigation__link:hover {
				background-color: #4C0827 !important;
			}

			#banner, .mdl-layout__drawer-button {
				color: #80D39B !important;
			}

			#banner {
				font-family: 'Comfortaa', cursive !important;
				font-size: 72px;
				text-align: center;
			}

			#banner>small {
				font-size: 24px;
			}

			h3, p {
				color: white;
			}

			h3 {
				text-align: center;
			}

			p {
				font-size: 16px;
			}

			h4 {
				font-size: 16px;
				color: white;
				text-align: center;
			}

			main::-webkit-scrollbar {
			    width: 1em;
			}
			 
			main::-webkit-scrollbar-track {
			    -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3);
			}
			 
			main::-webkit-scrollbar-thumb {
			  background-color: #4C0827;
			  outline: 1px solid slategrey;
			}
		</style>
	</head>
	<body>
		<div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
		  <header class="mdl-layout__header">
		    <div class="mdl-layout__header-row">
		    </div>
		  </header>
		  <main class="mdl-layout__content">
		    <div class="page-content">
		    	<h1 id="banner">
		    		Viseme <br>
		    		<small>Improving the accuracy of speech to text recognition through the use of lip reading</small>
		    	</h1>

		    	<h3>Inspiration</h3>
		    	<p class="mdl-cell mdl-cell--8-col mdl-cell--2-offset">
		    		Our main goal for Viseme is to assist those who are deaf or hearing impaired to better understand and communicate with those around them. Although speech-to-text recognition software already exists, its inability to recognize speech in loud noise conditions limits its effectiveness. By augmenting existing speech recognition systems with lip reading, Viseme transcends these constraints and provides more accurate predictions than ordinary speech-to-text solutions.
		    	</p>
		    	<h3>What it does</h3>
		    	<p class="mdl-cell mdl-cell--8-col mdl-cell--2-offset">
		    		Viseme uses the standard HTML5 Voice Recognition API for basic speech-to-text functionality. When ambient noise exceeds the threshold where voice recognition becomes no longer accurate, Viseme switches to device camera for lip reading. The video is streamed to Viseme machine learning engine running a neural network; recognized text is sent back to the frontend to be displayed as subtitles. Once the noise level drops, the system reverts back to audio-only speech-to-text recognition.
		    	</p>
		    	<h3>How we built it</h3>
		    	<p class="mdl-cell mdl-cell--8-col mdl-cell--2-offset">
		    		The machine learning engine driving Viseme is trained on speakers pronouncing sets of most commonly used phrases. Training videos are cropped down to speakersâ€™ lips and normalized spatially and temporally; the processed dataset is used to train a Multilayer Perceptron neural network.
					<br><br>
					Viseme's machine learning engine is based on the work by Bernstein, Leitman and Sandler of Ben Gurion University. Being one of the few open source lip reading solutions, the engine competes with Google Deepmind's state-of-the-art 46.8% accuracy achieved in 2016.
		    	</p>
		    	<h3>Challenges we ran into</h3>
		    	<p class="mdl-cell mdl-cell--8-col mdl-cell--2-offset">
		    		According to Prof. Richard Harvey of University of East Anglia, "lip-reading is one of the most challenging problems in artificial intelligence" (2016). This is an apt description of the problem we tackled.
					<br><br>
					An example of the problem we faced was compiling and building the aforementioned lips-reading library, which was created 5 years ago. Most of dependencies were out-dated, and it took considerable amount of time to get it running. Another challenge was connecting all the components: the frontend client, the backend server responsible for voice recognition and another server which was actually performing the lip reading. While it is infeasible to solve such a complex problem in a few days, we definitely managed to achieve great results and give inspiration for further projects in this area.
		    	</p>
		    	<h3>What we learned</h3>
		    	<p class="mdl-cell mdl-cell--8-col mdl-cell--2-offset">
		    		We learned a lot about the cutting edge research involved in lip reading AI and the many difficulties that surround the area. In doing so, we learned the principles and techniques required in implementing a viable solution. We also learned how to write a web socket server in Java that accepts a continuous stream of video frames from a client page, which turned out to be far more complicated than doing the same in Node.js.
		    	</p>
		    	<h3>What's next for Viseme</h3>
		    	<p class="mdl-cell mdl-cell--8-col mdl-cell--2-offset">
		    		The biggest step moving forward would be to increase the accuracy of the lip reading. To do so requires far more time and training data, and even more time to analyze the results and continue tweaking the algorithms. Continuing Viseme as a project would serve as a perfect research opportunity into the field of machine learning, and would result in an incredibly practical technology.
		    	</p>
		    	<h4><strong>TL;DR: Making a lip reading AI is pretty damn hard</strong></h4>
		    </div>
		  </main>
			<footer class="mdl-mini-footer">
				<div class="mdl-mini-footer__left-section">
					<ul class="mdl-mini-footer__link-list">
					  <li><a href="https://github.com/Viseme/server">Viseme Server</a></li>
					  <li><a href="https://github.com/Viseme/client">Visime Client</a></li>
					  <li><a href="https://devpost.com/software/viseme">Devpost Submission</a></li>
					</ul>
				</div>
			</footer>
		</div>
	</body>
</html>